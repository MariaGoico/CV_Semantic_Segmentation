{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from imageio import imread\n",
    "from torchvision. transforms. functional import to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CCPDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset para segmentación semántica multiclase. \n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'image_path', 'mask_path', y opcionalmente 'coords'\n",
    "        patch_size: Tamaño del patch a extraer\n",
    "        transforms: Lista [joint_transform, image_transform] donde:\n",
    "            - joint_transform: se aplica a imagen y máscara (ej: flips, rotaciones)\n",
    "            - image_transform: se aplica solo a imagen (ej: normalización)\n",
    "        mode: 'train' (random crop), 'eval' (crop con coords), 'full' (imagen completa)\n",
    "        class_dict_path: Ruta al CSV con columnas 'r', 'g', 'b' para mapeo de colores\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, patch_size=224, transforms=None, mode='train', class_dict_path='clothes/class_dict.csv'):\n",
    "        super(CCPDataset, self).__init__()\n",
    "        self.df = df. reset_index(drop=True)\n",
    "        self.ps = patch_size\n",
    "        self. transforms = transforms\n",
    "        self.mode = mode\n",
    "\n",
    "        # Cargar diccionario de clases\n",
    "        class_df = pd.read_csv(class_dict_path)\n",
    "        \n",
    "        # Crear mapping RGB -> class_id usando bit packing\n",
    "        r = class_df['r'].to_numpy(dtype=np.uint32)\n",
    "        g = class_df['g'].to_numpy(dtype=np.uint32)\n",
    "        b = class_df['b'].to_numpy(dtype=np.uint32)\n",
    "\n",
    "        keys = (r << 16) | (g << 8) | b\n",
    "\n",
    "        self.color_to_class = dict(zip(keys. tolist(), range(len(keys))))\n",
    "        self.num_classes = len(self.color_to_class)\n",
    "        \n",
    "        # Guardar nombres de clases si están disponibles\n",
    "        if 'class_name' in class_df.columns:\n",
    "            self.class_names = class_df['class_name']. tolist()\n",
    "            if self.class_names[0] == 'null':\n",
    "                self.class_names[0] = 'background'\n",
    "        else:\n",
    "            self.class_names = [f'class_{i}' for i in range(self.num_classes)]\n",
    "\n",
    "    def mask_rgb_to_ids(self, mask):\n",
    "        \"\"\"\n",
    "        Convierte máscara RGB a índices de clase usando bit packing.\n",
    "        Colores no encontrados se mapean a clase 0 (background).\n",
    "        \"\"\"\n",
    "        packed = (mask[...,0].astype(np.uint32) << 16) | \\\n",
    "                 (mask[...,1].astype(np.uint32) << 8)  | \\\n",
    "                  mask[...,2].astype(np.uint32)\n",
    "        \n",
    "        # Verificar colores desconocidos (opcional, comentar si no necesitas warnings)\n",
    "        unique_packed = np.unique(packed)\n",
    "        unknown = [p for p in unique_packed if p not in self.color_to_class]\n",
    "        if unknown and self.mode == 'train':  # Solo warning en train para no saturar logs\n",
    "            unknown_colors = [(p >> 16, (p >> 8) & 0xFF, p & 0xFF) for p in unknown[:3]]\n",
    "            print(f\"Warning: Found {len(unknown)} unknown colors (showing first 3): {unknown_colors}\")\n",
    "        \n",
    "        mapped = np.vectorize(self.color_to_class.get)(packed, 0)\n",
    "        return mapped. astype(np.int64)\n",
    "\n",
    "    def __random_crop__(self, img, mask):\n",
    "        \"\"\"Extrae un crop aleatorio de tamaño self.ps\"\"\"\n",
    "        H, W = img. shape[:2]\n",
    "        \n",
    "        if H < self.ps or W < self. ps:\n",
    "            # Padding si la imagen es más pequeña que el patch\n",
    "            pad_h = max(0, self.ps - H)\n",
    "            pad_w = max(0, self.ps - W)\n",
    "            img = np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect')\n",
    "            mask = np.pad(mask, ((0, pad_h), (0, pad_w), (0, 0)) if mask. ndim == 3 else ((0, pad_h), (0, pad_w)), mode='reflect')\n",
    "            H, W = img.shape[:2]\n",
    "        \n",
    "        # Random top-left corner\n",
    "        top = np.random.randint(0, H - self.ps + 1)\n",
    "        left = np.random.randint(0, W - self.ps + 1)\n",
    "        \n",
    "        # Extract patch\n",
    "        img_patch = img[top:top+self.ps, left:left+self.ps]\n",
    "        mask_patch = mask[top:top+self.ps, left:left+self.ps]\n",
    "        \n",
    "        return img_patch, mask_patch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.df. iloc[idx]\n",
    "\n",
    "        # Leer imagen y máscara\n",
    "        x = imread(r.image_path)\n",
    "        y = imread(r.mask_path)\n",
    "\n",
    "        # Aplicar crop según el modo\n",
    "        if self.mode == 'train':\n",
    "            # Random crop para entrenamiento\n",
    "            x, y = self.__random_crop__(x, y)\n",
    "            \n",
    "        elif self.mode == 'eval':\n",
    "            # Crop con coordenadas específicas para evaluación\n",
    "            if 'coords' in r and r.coords is not None:\n",
    "                x = x[r.coords[0]:r.coords[0]+self.ps, r.coords[1]:r.coords[1]+self.ps]\n",
    "                y = y[r.coords[0]:r.coords[0]+self.ps, r.coords[1]:r.coords[1]+self.ps]\n",
    "            else:\n",
    "                # Si no hay coords, tomar centro\n",
    "                H, W = x.shape[:2]\n",
    "                top = max(0, (H - self.ps) // 2)\n",
    "                left = max(0, (W - self.ps) // 2)\n",
    "                x = x[top:top+self.ps, left:left+self.ps]\n",
    "                y = y[top:top+self.ps, left:left+self.ps]\n",
    "        \n",
    "        # mode == 'full': no hacer crop, usar imagen completa\n",
    "\n",
    "        # Convertir máscara RGB a IDs de clase\n",
    "        if y.ndim == 3 and y.shape[2] == 3:\n",
    "            y = self.mask_rgb_to_ids(y)\n",
    "        else:\n",
    "            y = y.astype(np.int64)\n",
    "\n",
    "        # Convertir a PIL para aplicar transforms\n",
    "        x = to_pil_image(x. astype('float32'))\n",
    "        y = to_pil_image(y.astype('uint8'), mode='L')\n",
    "\n",
    "        # Aplicar transformaciones\n",
    "        if self. transforms:\n",
    "            if isinstance(self.transforms, list):\n",
    "                # Formato: [joint_transform, image_transform]\n",
    "                if self.transforms[0] is not None:\n",
    "                    x, y = self.transforms[0](x, y)\n",
    "                if self.transforms[1] is not None:\n",
    "                    x = self. transforms[1](x)\n",
    "            else:\n",
    "                # Solo image transform\n",
    "                x = self.transforms(x)\n",
    "\n",
    "        # Convertir a tensors\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.from_numpy(np.array(x)). permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        y = torch.from_numpy(np.array(y, dtype=np.int64))\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __show_item__(self, x, y, denormalize=None):\n",
    "        \"\"\"\n",
    "        Visualiza una muestra del dataset.\n",
    "        \n",
    "        Args:\n",
    "            x: Tensor de imagen (C, H, W)\n",
    "            y: Tensor de máscara (H, W)\n",
    "            denormalize: Función para desnormalizar la imagen (opcional)\n",
    "        \"\"\"\n",
    "        f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        # Desnormalizar imagen si es necesario\n",
    "        if denormalize is not None:\n",
    "            x_vis = denormalize(x)\n",
    "        else:\n",
    "            x_vis = x\n",
    "        \n",
    "        # Asegurar que x esté en rango [0, 1]\n",
    "        x_vis = x_vis.permute(1, 2, 0).cpu().numpy()\n",
    "        if x_vis.max() > 1.0:\n",
    "            x_vis = x_vis / 255.0\n",
    "        x_vis = np.clip(x_vis, 0, 1)\n",
    "\n",
    "        y_vis = y.cpu().numpy()\n",
    "\n",
    "        ax[0].imshow(x_vis)\n",
    "        ax[0].set_title('Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(y_vis, cmap='tab20', vmin=0, vmax=self.num_classes-1)\n",
    "        ax[1]. set_title('Mask')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(x_vis)\n",
    "        ax[2].imshow(y_vis, alpha=0.5, cmap='tab20', vmin=0, vmax=self.num_classes-1)\n",
    "        ax[2].set_title('Overlay')\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torch\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning DataModule para segmentación semántica. \n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'image_path', 'mask_path', 'set'\n",
    "        class_dict_path: Ruta al CSV con clases\n",
    "        bs: Batch size\n",
    "        ps: Patch size\n",
    "        num_workers: Número de workers para DataLoader\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, class_dict_path='clothes/class_dict.csv', bs=16, ps=256, num_workers=8):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.class_dict_path = class_dict_path\n",
    "        self.bs = bs\n",
    "        self.ps = ps\n",
    "        self. num_workers = num_workers\n",
    "        \n",
    "        # Cargar número de clases\n",
    "        class_df = pd.read_csv(class_dict_path)\n",
    "        self.num_classes = len(class_df)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Preparar datasets con transforms apropiados\"\"\"\n",
    "        \n",
    "        # Transforms para normalización (solo imagen)\n",
    "        normalize_transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T. Normalize(mean=[0.485, 0.456, 0. 406], std=[0.229, 0.224, 0. 225]),\n",
    "        ])\n",
    "        \n",
    "        # Para train: sin joint transforms (podrías agregar data augmentation aquí)\n",
    "        train_transforms = [None, normalize_transform]\n",
    "        \n",
    "        # Para val/test: solo normalización\n",
    "        eval_transforms = [None, normalize_transform]\n",
    "        \n",
    "        # Crear datasets\n",
    "        self.train_ds = CCPDataset(\n",
    "            df=self.df. query('set == \"train\"'). reset_index(drop=True),\n",
    "            patch_size=self. ps,\n",
    "            transforms=train_transforms,\n",
    "            mode='train',\n",
    "            class_dict_path=self.class_dict_path\n",
    "        )\n",
    "        \n",
    "        self. valid_ds = CCPDataset(\n",
    "            df=self.df. query('set == \"valid\"').reset_index(drop=True),\n",
    "            patch_size=self.ps,\n",
    "            transforms=eval_transforms,\n",
    "            mode='train',  # También random crop en validación\n",
    "            class_dict_path=self.class_dict_path\n",
    "        )\n",
    "        \n",
    "        self.test_ds = CCPDataset(\n",
    "            df=self. df.query('set == \"test\"').reset_index(drop=True),\n",
    "            patch_size=self.ps,\n",
    "            transforms=eval_transforms,\n",
    "            mode='full',  # Imagen completa para test\n",
    "            class_dict_path=self.class_dict_path\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.bs,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_ds,\n",
    "            batch_size=self.bs,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=1,  # Batch size 1 para imágenes completas\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def patch_origins(h, w, ps, overlap=2):\n",
    "        \"\"\"\n",
    "        Genera coordenadas de origen para patches con overlap.\n",
    "        \n",
    "        Args:\n",
    "            h, w: Alto y ancho de la imagen\n",
    "            ps: Tamaño del patch\n",
    "            overlap: Factor de overlap (overlap=2 significa 50% de overlap)\n",
    "        \n",
    "        Returns:\n",
    "            Array de coordenadas (x, y) de origen de cada patch\n",
    "        \"\"\"\n",
    "        stride = ps // overlap\n",
    "        origins = []\n",
    "        \n",
    "        for x in range(0, h - ps + 1, stride):\n",
    "            for y in range(0, w - ps + 1, stride):\n",
    "                origins.append([x, y])\n",
    "        \n",
    "        # Agregar bordes si no están cubiertos\n",
    "        if (h - ps) % stride != 0:\n",
    "            for y in range(0, w - ps + 1, stride):\n",
    "                origins.append([h - ps, y])\n",
    "        \n",
    "        if (w - ps) % stride != 0:\n",
    "            for x in range(0, h - ps + 1, stride):\n",
    "                origins.append([x, w - ps])\n",
    "        \n",
    "        # Esquina inferior derecha\n",
    "        if (h - ps) % stride != 0 and (w - ps) % stride != 0:\n",
    "            origins. append([h - ps, w - ps])\n",
    "        \n",
    "        return np.array(origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch. nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import defaultdict\n",
    "\n",
    "class SegmentationModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning Module para segmentación semántica multiclase.\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Número de clases de segmentación\n",
    "        encoder_name: Nombre del encoder (ej: 'resnet18', 'resnet50', 'efficientnet-b0')\n",
    "        encoder_weights: Pesos pre-entrenados (ej: 'imagenet')\n",
    "        learning_rate: Learning rate para el optimizador\n",
    "        architecture: Arquitectura del modelo ('unet', 'unet++', 'deeplabv3+', etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, encoder_name='resnet18', encoder_weights='imagenet', \n",
    "                 learning_rate=1e-3, architecture='unet'):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Crear modelo según arquitectura\n",
    "        if architecture == 'unet':\n",
    "            self.model = smp.Unet(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                in_channels=3,\n",
    "                classes=num_classes\n",
    "            )\n",
    "        elif architecture == 'unet++':\n",
    "            self.model = smp.UnetPlusPlus(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                in_channels=3,\n",
    "                classes=num_classes\n",
    "            )\n",
    "        elif architecture == 'deeplabv3+':\n",
    "            self.model = smp.DeepLabV3Plus(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                in_channels=3,\n",
    "                classes=num_classes\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Architecture {architecture} not supported\")\n",
    "        \n",
    "        # Métricas acumuladas por época\n",
    "        self.training_step_outputs = defaultdict(float)\n",
    "        self.validation_step_outputs = defaultdict(float)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch. optim.lr_scheduler. ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0. 5,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        # Redimensionar logits si es necesario\n",
    "        if logits.shape[-2:] != y.shape[-2:]:\n",
    "            logits = F.interpolate(logits, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calcular loss\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Calcular accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        # Logging\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        self.training_step_outputs['loss'] += loss.detach().cpu()\n",
    "        self.training_step_outputs['acc'] += acc.detach().cpu()\n",
    "        self.training_step_outputs['steps'] += 1\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        # Redimensionar logits si es necesario\n",
    "        if logits.shape[-2:] != y.shape[-2:]:\n",
    "            logits = F.interpolate(logits, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Calcular loss\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Calcular accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        # Logging\n",
    "        self. log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs['loss'] += loss.detach().cpu()\n",
    "        self.validation_step_outputs['acc'] += acc.detach(). cpu()\n",
    "        self.validation_step_outputs['steps'] += 1\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.training_step_outputs['steps'] > 0:\n",
    "            avg_loss = self.training_step_outputs['loss'] / self.training_step_outputs['steps']\n",
    "            avg_acc = self.training_step_outputs['acc'] / self.training_step_outputs['steps']\n",
    "            print(f\"\\nEpoch {self.current_epoch} - Train Loss: {avg_loss:. 4f}, Train Acc: {avg_acc:.4f}\")\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.validation_step_outputs['steps'] > 0:\n",
    "            avg_loss = self.validation_step_outputs['loss'] / self. validation_step_outputs['steps']\n",
    "            avg_acc = self. validation_step_outputs['acc'] / self.validation_step_outputs['steps']\n",
    "            print(f\"Epoch {self.current_epoch} - Val Loss: {avg_loss:.4f}, Val Acc: {avg_acc:.4f}\")\n",
    "        self.validation_step_outputs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# 1.  PREPARAR DATOS\n",
    "# ============================================\n",
    "\n",
    "DATA_DIR = 'clothes'\n",
    "\n",
    "# Cargar imágenes\n",
    "images = glob.glob('./clothes/*/images/*')\n",
    "df = pd.DataFrame(images, columns=['image_path'])\n",
    "df['mask_path'] = df. image_path.apply(lambda x: x.replace('/images/', '/labels/'). replace('. jpg', '.png'))\n",
    "df['set'] = df.image_path.apply(lambda x: x.split('/')[2])\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(df['set'].value_counts())\n",
    "print(df. head())\n",
    "\n",
    "# Cargar diccionario de clases\n",
    "class_dict = pd.read_csv(os.path.join(DATA_DIR, 'class_dict. csv'))\n",
    "class_names = class_dict['class_name'].tolist()\n",
    "class_names[0] = 'background'  # Renombrar 'null' a 'background'\n",
    "class_rgb_values = class_dict[['r', 'g', 'b']].values.tolist()\n",
    "\n",
    "print('\\n' + '='*50)\n",
    "print('Dataset Classes:')\n",
    "print('='*50)\n",
    "for i, (name, rgb) in enumerate(zip(class_names, class_rgb_values)):\n",
    "    print(f\"{i:2d}. {name:20s} - RGB: {rgb}\")\n",
    "print('='*50 + '\\n')\n",
    "\n",
    "# ============================================\n",
    "# 2. CREAR DATAMODULE\n",
    "# ============================================\n",
    "\n",
    "dm = DataModule(\n",
    "    df=df,\n",
    "    class_dict_path=os.path.join(DATA_DIR, 'class_dict.csv'),\n",
    "    bs=16,\n",
    "    ps=256,\n",
    "    num_workers=4  # Ajusta según tu CPU\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "print(f\"Train samples: {len(dm.train_ds)}\")\n",
    "print(f\"Valid samples: {len(dm. valid_ds)}\")\n",
    "print(f\"Test samples: {len(dm.test_ds)}\")\n",
    "print(f\"Number of classes: {dm.num_classes}\")\n",
    "\n",
    "# ============================================\n",
    "# 3.  VISUALIZAR MUESTRAS\n",
    "# ============================================\n",
    "\n",
    "# Visualizar algunas muestras de entrenamiento\n",
    "for i in range(3):\n",
    "    x, y = dm.train_ds[i]\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Image shape: {x.shape}\")\n",
    "    print(f\"Mask shape: {y.shape}\")\n",
    "    print(f\"Unique classes in mask: {torch.unique(y). tolist()}\")\n",
    "    dm.train_ds.__show_item__(x, y)\n",
    "\n",
    "# ============================================\n",
    "# 4. CREAR MODELO\n",
    "# ============================================\n",
    "\n",
    "model = SegmentationModel(\n",
    "    num_classes=dm.num_classes,\n",
    "    encoder_name='resnet18',\n",
    "    encoder_weights='imagenet',\n",
    "    learning_rate=1e-3,\n",
    "    architecture='unet'\n",
    ")\n",
    "\n",
    "print(f\"\\nModel created with {dm.num_classes} classes\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. ENTRENAR\n",
    "# ============================================\n",
    "\n",
    "from pytorch_lightning. callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints',\n",
    "    filename='segmentation-{epoch:02d}-{val_loss:.4f}',\n",
    "    save_top_k=3,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger('logs', name='segmentation')\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    precision='16-mixed' if torch.cuda.is_available() else 32  # Mixed precision para GPU\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best model: {checkpoint_callback.best_model_path}\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1498dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torchvision.transforms. functional import to_pil_image\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
    "import torch. nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rgb_to_class(mask, class_rgb_values):\n",
    "    \"\"\"Convertir máscara RGB a índices de clase\"\"\"\n",
    "    h, w, _ = mask.shape\n",
    "    class_mask = np.zeros((h, w), dtype=np.int64)\n",
    "    \n",
    "    for idx, rgb in enumerate(class_rgb_values):\n",
    "        matches = np.all(mask == np.array(rgb), axis=-1)\n",
    "        class_mask[matches] = idx\n",
    "    \n",
    "    return class_mask\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURACIÓN\n",
    "# ============================================\n",
    "\n",
    "ps = 256\n",
    "\n",
    "# Cargar mejor modelo\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = SegmentationModel. load_from_checkpoint(best_model_path)\n",
    "model.eval()\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "\n",
    "# Transforms para inferencia\n",
    "inf_transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T. Normalize(mean=[0.485, 0.456, 0. 406], std=[0.229, 0.224, 0. 225]),\n",
    "])\n",
    "\n",
    "# ============================================\n",
    "# INFERENCIA EN TEST SET\n",
    "# ============================================\n",
    "\n",
    "metric_dict = []\n",
    "test_df = df.query('set == \"test\"').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nRunning inference on {len(test_df)} test images.. .\\n\")\n",
    "\n",
    "for i in tqdm(range(len(test_df)), desc=\"Processing images\"):\n",
    "    r = test_df.iloc[i]\n",
    "\n",
    "    # Leer imagen y máscara\n",
    "    x = imread(r.image_path)\n",
    "    y = imread(r.mask_path)\n",
    "    \n",
    "    # Convertir máscara RGB a índices de clase\n",
    "    if y.ndim == 3 and y.shape[2] == 3:\n",
    "        # Usar el método eficiente con bit packing\n",
    "        packed = (y[...,0]. astype(np.uint32) << 16) | \\\n",
    "                 (y[...,1].astype(np.uint32) << 8) | \\\n",
    "                 y[...,2].astype(np.uint32)\n",
    "        \n",
    "        color_to_class = dm.train_ds.color_to_class\n",
    "        y = np.vectorize(color_to_class. get)(packed, 0). astype(np.int64)\n",
    "    \n",
    "    # Obtener dimensiones\n",
    "    h, w = y.shape\n",
    "    \n",
    "    # Generar coordenadas de patches\n",
    "    coords = DataModule.patch_origins(h, w, ps=ps, overlap=2)\n",
    "\n",
    "    # Inicializar predicciones\n",
    "    y_hat = torch.zeros((dm.num_classes, h, w), dtype=torch.float32)\n",
    "    y_wei = torch.zeros((1, h, w), dtype=torch.uint8)\n",
    "    \n",
    "    # Realizar inferencia por patches\n",
    "    for (coord_x, coord_y) in coords:\n",
    "        \n",
    "        # Extraer patch\n",
    "        xi = x[coord_x:coord_x+ps, coord_y:coord_y+ps]\n",
    "        \n",
    "        # Convertir a PIL\n",
    "        xi = to_pil_image(xi. astype('float32'))\n",
    "        \n",
    "        # Aplicar transforms\n",
    "        xi = inf_transforms(xi)\n",
    "        \n",
    "        # Inferencia\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                logits = model(xi.cuda(). unsqueeze(0))\n",
    "            else:\n",
    "                logits = model(xi.unsqueeze(0))\n",
    "            \n",
    "            logits = nn. Softmax(dim=1)(logits). detach().cpu()[0]\n",
    "        \n",
    "        # Acumular predicciones\n",
    "        y_hat[:, coord_x:coord_x+ps, coord_y:coord_y+ps] += logits\n",
    "        y_wei[:, coord_x:coord_x+ps, coord_y:coord_y+ps] += 1\n",
    "    \n",
    "    # Normalizar predicciones\n",
    "    y_hat /= y_wei\n",
    "    y_hat_pred = y_hat.argmax(0). numpy()\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metric_dict.append({\n",
    "        'image': r.image_path,\n",
    "        'pixel_acc': accuracy_score(y. ravel(), y_hat_pred. ravel()),\n",
    "        'iou_macro': jaccard_score(y. ravel(), y_hat_pred.ravel(), average='macro', zero_division=0),\n",
    "        'iou_weighted': jaccard_score(y. ravel(), y_hat_pred.ravel(), average='weighted', zero_division=0),\n",
    "        'dice_macro': f1_score(y.ravel(), y_hat_pred.ravel(), average='macro', zero_division=0),\n",
    "        'dice_weighted': f1_score(y.ravel(), y_hat_pred.ravel(), average='weighted', zero_division=0)\n",
    "    })\n",
    "\n",
    "# ============================================\n",
    "# MOSTRAR RESULTADOS\n",
    "# ============================================\n",
    "\n",
    "results_df = pd.DataFrame(metric_dict)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INFERENCE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.describe())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEAN METRICS:\")\n",
    "print(\"=\"*80)\n",
    "for col in ['pixel_acc', 'iou_macro', 'iou_weighted', 'dice_macro', 'dice_weighted']:\n",
    "    print(f\"{col:20s}: {results_df[col].mean():.4f} ± {results_df[col].std():.4f}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_df.to_csv('test_results.csv', index=False)\n",
    "print(\"Results saved to 'test_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b39654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(image_path, model, transforms, class_names, ps=256, overlap=2):\n",
    "    \"\"\"\n",
    "    Visualiza la predicción de segmentación para una imagen. \n",
    "    \"\"\"\n",
    "    # Leer imagen\n",
    "    x = imread(image_path)\n",
    "    h, w = x.shape[:2]\n",
    "    \n",
    "    # Generar patches\n",
    "    coords = DataModule.patch_origins(h, w, ps=ps, overlap=overlap)\n",
    "    \n",
    "    # Inicializar predicciones\n",
    "    num_classes = len(class_names)\n",
    "    y_hat = torch.zeros((num_classes, h, w), dtype=torch.float32)\n",
    "    y_wei = torch.zeros((1, h, w), dtype=torch.uint8)\n",
    "    \n",
    "    # Inferencia\n",
    "    model.eval()\n",
    "    for (coord_x, coord_y) in tqdm(coords, desc=\"Predicting\"):\n",
    "        xi = x[coord_x:coord_x+ps, coord_y:coord_y+ps]\n",
    "        xi = to_pil_image(xi. astype('float32'))\n",
    "        xi = transforms(xi)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                logits = model(xi.cuda().unsqueeze(0))\n",
    "            else:\n",
    "                logits = model(xi.unsqueeze(0))\n",
    "            logits = nn.Softmax(dim=1)(logits).detach().cpu()[0]\n",
    "        \n",
    "        y_hat[:, coord_x:coord_x+ps, coord_y:coord_y+ps] += logits\n",
    "        y_wei[:, coord_x:coord_x+ps, coord_y:coord_y+ps] += 1\n",
    "    \n",
    "    # Normalizar y obtener predicción\n",
    "    y_hat /= y_wei\n",
    "    y_pred = y_hat.argmax(0).numpy()\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(x)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(y_pred, cmap='tab20', vmin=0, vmax=num_classes-1)\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(x)\n",
    "    axes[2].imshow(y_pred, alpha=0.5, cmap='tab20', vmin=0, vmax=num_classes-1)\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar distribución de clases\n",
    "    unique, counts = np.unique(y_pred, return_counts=True)\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for cls, count in zip(unique, counts):\n",
    "        percentage = 100 * count / y_pred.size\n",
    "        print(f\"  {class_names[cls]:20s}: {percentage:6.2f}%\")\n",
    "\n",
    "# Uso:\n",
    "# visualize_prediction(\n",
    "#     test_df. iloc[0]. image_path, \n",
    "#     model, \n",
    "#     inf_transforms, \n",
    "#     class_names,\n",
    "#     ps=256,\n",
    "#     overlap=2\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
